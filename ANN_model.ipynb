{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tasosnikitakis/Machine-and-Deep-Learning/blob/main/ANN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ann_visualizer"
      ],
      "metadata": {
        "id": "iE5YvqqegLpK",
        "outputId": "90c51307-2bd7-466a-8a02-5146a50138f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ann_visualizer\n",
            "  Downloading ann_visualizer-2.5.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ann_visualizer\n",
            "  Building wheel for ann_visualizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ann_visualizer: filename=ann_visualizer-2.5-py3-none-any.whl size=4167 sha256=b0c31581192e90c071eb4d8e097b2ffe91814b190ef62c78a3e7f1f6c6bea392\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/0f/ae/f5dba91db71b1b32bf03d0ad18c32e86126093aba5ec6b6488\n",
            "Successfully built ann_visualizer\n",
            "Installing collected packages: ann_visualizer\n",
            "Successfully installed ann_visualizer-2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install visualkeras"
      ],
      "metadata": {
        "id": "adc5mz9pkdIR",
        "outputId": "c14f0b1d-c734-4284-d14e-e5387c87e407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.22.4)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.0/993.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.16 visualkeras-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3JJzrofyiiWf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SXMqfkSQiiWh",
        "outputId": "dfd5fb21-8c5d-4fa3-c6d9-4bbcb2a261b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jI4xLsF7iiWi"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "x = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6CD0ho4iiWi",
        "outputId": "fa537f3c-e430-4f5d-9fe6-f11be94c4ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIO0-Sn7iiWi",
        "outputId": "0e253324-43ab-4194-f797-2433e12cb359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SjYKiIcwiiWj"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "x[:, 2] = le.fit_transform(x[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS1i7gFviiWk",
        "outputId": "897c719c-3981-419e-deae-6dd68e8a5b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6pzmS2VgiiWl"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anx5_5A2iiWl",
        "outputId": "70352419-3c23-45b3-b9c8-8c426ea31b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kJibWZnqiiWl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keqae9ThiiWm",
        "outputId": "d56a069a-2c8b-4178-9f8d-9fb8293e0d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 ... 0 1 124749.08]\n",
            " [1.0 0.0 0.0 ... 0 0 41104.82]\n",
            " [0.0 1.0 0.0 ... 1 1 45750.21]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 1 1 92027.69]\n",
            " [1.0 0.0 0.0 ... 1 1 101168.9]\n",
            " [0.0 1.0 0.0 ... 1 0 33462.94]]\n"
          ]
        }
      ],
      "source": [
        "print(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpTxHGQjiiWm",
        "outputId": "a4ef4f2a-6fd8-4682-f9ac-fb3205bea3c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 97057.28]\n",
            " [1.0 0.0 0.0 ... 1 0 66526.01]\n",
            " [1.0 0.0 0.0 ... 0 1 90537.47]\n",
            " ...\n",
            " [0.0 0.0 1.0 ... 0 1 161571.79]\n",
            " [0.0 1.0 0.0 ... 1 1 165257.31]\n",
            " [0.0 1.0 0.0 ... 1 1 49025.79]]\n"
          ]
        }
      ],
      "source": [
        "print(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W-OR3hciiWn",
        "outputId": "ddbb9638-5c0e-48fb-eb7f-29e42b049b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 ... 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ywYOKDSiiWn",
        "outputId": "bdbf04fa-d535-4acd-a023-6ad580f3506f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Wc6OCS_piiWo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbgyLusRiiWp",
        "outputId": "fadeff85-59cb-4fd0-8e54-47ee9d497a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.99850112  1.71490137 -0.57273139 ... -1.55337352  0.97725852\n",
            "   0.42739449]\n",
            " [ 1.00150113 -0.58312392 -0.57273139 ... -1.55337352 -1.02327069\n",
            "  -1.02548708]\n",
            " [-0.99850112  1.71490137 -0.57273139 ...  0.64376017  0.97725852\n",
            "  -0.94479772]\n",
            " ...\n",
            " [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n",
            "  -0.14096853]\n",
            " [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n",
            "   0.01781218]\n",
            " [-0.99850112  1.71490137 -0.57273139 ...  0.64376017 -1.02327069\n",
            "  -1.15822478]]\n"
          ]
        }
      ],
      "source": [
        "print(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kGMuejbiiWp",
        "outputId": "b139a292-a405-4c50-c172-ff3e68c08986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017  0.97725852\n",
            "  -0.05360571]\n",
            " [ 1.00150113 -0.58312392 -0.57273139 ...  0.64376017 -1.02327069\n",
            "  -0.58392685]\n",
            " [ 1.00150113 -0.58312392 -0.57273139 ... -1.55337352  0.97725852\n",
            "  -0.16685331]\n",
            " ...\n",
            " [-0.99850112 -0.58312392  1.74601919 ... -1.55337352  0.97725852\n",
            "   1.0669965 ]\n",
            " [-0.99850112  1.71490137 -0.57273139 ...  0.64376017  0.97725852\n",
            "   1.13101314]\n",
            " [-0.99850112  1.71490137 -0.57273139 ...  0.64376017  0.97725852\n",
            "  -0.88790165]]\n"
          ]
        }
      ],
      "source": [
        "print(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fEOQc7sLiiWq"
      },
      "outputs": [],
      "source": [
        "ann = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vt8qNLjviiWq"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation = \"relu\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dB-jHgvOiiWr"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation = \"relu\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vcULZ1SciiWr"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation = \"sigmoid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YKo2khn_iiWs"
      },
      "outputs": [],
      "source": [
        "ann.compile(optimizer= \"adam\", loss= \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9hxdbBwiiWt",
        "outputId": "856a82ef-12d8-4496-e036-cf914d02672c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "250/250 [==============================] - 2s 3ms/step - loss: 0.5645 - accuracy: 0.7598\n",
            "Epoch 2/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7972\n",
            "Epoch 3/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7986\n",
            "Epoch 4/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8175\n",
            "Epoch 5/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8275\n",
            "Epoch 6/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8356\n",
            "Epoch 7/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8405\n",
            "Epoch 8/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8422\n",
            "Epoch 9/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8474\n",
            "Epoch 10/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8489\n",
            "Epoch 11/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8487\n",
            "Epoch 12/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8505\n",
            "Epoch 13/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8526\n",
            "Epoch 14/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8537\n",
            "Epoch 15/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8546\n",
            "Epoch 16/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8547\n",
            "Epoch 17/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8560\n",
            "Epoch 18/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8554\n",
            "Epoch 19/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8564\n",
            "Epoch 20/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8562\n",
            "Epoch 21/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8562\n",
            "Epoch 22/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.8568\n",
            "Epoch 23/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3447 - accuracy: 0.8587\n",
            "Epoch 24/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8585\n",
            "Epoch 25/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8585\n",
            "Epoch 26/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3437 - accuracy: 0.8591\n",
            "Epoch 27/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8574\n",
            "Epoch 28/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8593\n",
            "Epoch 29/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8597\n",
            "Epoch 30/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8595\n",
            "Epoch 31/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8594\n",
            "Epoch 32/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8594\n",
            "Epoch 33/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8580\n",
            "Epoch 34/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8591\n",
            "Epoch 35/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8585\n",
            "Epoch 36/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8590\n",
            "Epoch 37/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8579\n",
            "Epoch 38/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8590\n",
            "Epoch 39/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8604\n",
            "Epoch 40/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8589\n",
            "Epoch 41/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8593\n",
            "Epoch 42/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8585\n",
            "Epoch 43/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8599\n",
            "Epoch 44/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8605\n",
            "Epoch 45/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8602\n",
            "Epoch 46/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8597\n",
            "Epoch 47/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8616\n",
            "Epoch 48/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8604\n",
            "Epoch 49/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8606\n",
            "Epoch 50/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8604\n",
            "Epoch 51/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8608\n",
            "Epoch 52/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8608\n",
            "Epoch 53/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8600\n",
            "Epoch 54/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8610\n",
            "Epoch 55/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8610\n",
            "Epoch 56/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8611\n",
            "Epoch 57/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8596\n",
            "Epoch 58/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8604\n",
            "Epoch 59/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8614\n",
            "Epoch 60/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8615\n",
            "Epoch 61/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8611\n",
            "Epoch 62/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8596\n",
            "Epoch 63/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8622\n",
            "Epoch 64/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8606\n",
            "Epoch 65/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8615\n",
            "Epoch 66/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8621\n",
            "Epoch 67/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8602\n",
            "Epoch 68/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8614\n",
            "Epoch 69/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8606\n",
            "Epoch 70/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8609\n",
            "Epoch 71/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8619\n",
            "Epoch 72/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8605\n",
            "Epoch 73/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8618\n",
            "Epoch 74/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8611\n",
            "Epoch 75/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8612\n",
            "Epoch 76/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8618\n",
            "Epoch 77/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8606\n",
            "Epoch 78/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8619\n",
            "Epoch 79/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8616\n",
            "Epoch 80/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8610\n",
            "Epoch 81/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8599\n",
            "Epoch 82/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8612\n",
            "Epoch 83/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8629\n",
            "Epoch 84/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8597\n",
            "Epoch 85/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8610\n",
            "Epoch 86/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8606\n",
            "Epoch 87/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8609\n",
            "Epoch 88/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8602\n",
            "Epoch 89/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8591\n",
            "Epoch 90/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8604\n",
            "Epoch 91/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8614\n",
            "Epoch 92/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8621\n",
            "Epoch 93/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8601\n",
            "Epoch 94/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8604\n",
            "Epoch 95/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8619\n",
            "Epoch 96/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8610\n",
            "Epoch 97/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8602\n",
            "Epoch 98/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8597\n",
            "Epoch 99/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8601\n",
            "Epoch 100/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8627\n",
            "Epoch 101/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8619\n",
            "Epoch 102/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8593\n",
            "Epoch 103/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8611\n",
            "Epoch 104/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8622\n",
            "Epoch 105/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8606\n",
            "Epoch 106/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8595\n",
            "Epoch 107/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8602\n",
            "Epoch 108/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8601\n",
            "Epoch 109/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8601\n",
            "Epoch 110/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8612\n",
            "Epoch 111/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8616\n",
            "Epoch 112/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8595\n",
            "Epoch 113/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8619\n",
            "Epoch 114/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8614\n",
            "Epoch 115/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8610\n",
            "Epoch 116/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8620\n",
            "Epoch 117/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8606\n",
            "Epoch 118/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8600\n",
            "Epoch 119/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8597\n",
            "Epoch 120/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8609\n",
            "Epoch 121/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8616\n",
            "Epoch 122/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8615\n",
            "Epoch 123/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8616\n",
            "Epoch 124/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8609\n",
            "Epoch 125/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8610\n",
            "Epoch 126/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8609\n",
            "Epoch 127/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8616\n",
            "Epoch 128/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8614\n",
            "Epoch 129/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8621\n",
            "Epoch 130/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8608\n",
            "Epoch 131/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8612\n",
            "Epoch 132/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8612\n",
            "Epoch 133/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8624\n",
            "Epoch 134/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8616\n",
            "Epoch 135/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8629\n",
            "Epoch 136/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8621\n",
            "Epoch 137/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8622\n",
            "Epoch 138/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8627\n",
            "Epoch 139/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8622\n",
            "Epoch 140/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8619\n",
            "Epoch 141/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8630\n",
            "Epoch 142/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8624\n",
            "Epoch 143/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8630\n",
            "Epoch 144/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8610\n",
            "Epoch 145/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8633\n",
            "Epoch 146/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8626\n",
            "Epoch 147/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8621\n",
            "Epoch 148/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8624\n",
            "Epoch 149/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8618\n",
            "Epoch 150/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8619\n",
            "Epoch 151/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8625\n",
            "Epoch 152/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8634\n",
            "Epoch 153/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8629\n",
            "Epoch 154/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8624\n",
            "Epoch 155/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8620\n",
            "Epoch 156/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8630\n",
            "Epoch 157/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8619\n",
            "Epoch 158/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8634\n",
            "Epoch 159/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8634\n",
            "Epoch 160/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8636\n",
            "Epoch 161/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8630\n",
            "Epoch 162/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8639\n",
            "Epoch 163/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8633\n",
            "Epoch 164/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8626\n",
            "Epoch 165/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8622\n",
            "Epoch 166/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8625\n",
            "Epoch 167/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8629\n",
            "Epoch 168/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8639\n",
            "Epoch 169/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8634\n",
            "Epoch 170/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8629\n",
            "Epoch 171/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8631\n",
            "Epoch 172/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8621\n",
            "Epoch 173/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8635\n",
            "Epoch 174/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8635\n",
            "Epoch 175/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 176/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8624\n",
            "Epoch 177/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8629\n",
            "Epoch 178/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8622\n",
            "Epoch 179/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8616\n",
            "Epoch 180/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8634\n",
            "Epoch 181/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8645\n",
            "Epoch 182/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 183/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8645\n",
            "Epoch 184/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8631\n",
            "Epoch 185/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8643\n",
            "Epoch 186/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8633\n",
            "Epoch 187/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8633\n",
            "Epoch 188/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8634\n",
            "Epoch 189/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8633\n",
            "Epoch 190/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 191/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8631\n",
            "Epoch 192/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8631\n",
            "Epoch 193/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8645\n",
            "Epoch 194/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8627\n",
            "Epoch 195/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8635\n",
            "Epoch 196/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8635\n",
            "Epoch 197/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8646\n",
            "Epoch 198/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8643\n",
            "Epoch 199/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 200/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8611\n",
            "Epoch 201/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8646\n",
            "Epoch 202/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8631\n",
            "Epoch 203/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8643\n",
            "Epoch 204/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8633\n",
            "Epoch 205/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8640\n",
            "Epoch 206/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8652\n",
            "Epoch 207/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8646\n",
            "Epoch 208/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8645\n",
            "Epoch 209/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8646\n",
            "Epoch 210/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8640\n",
            "Epoch 211/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8641\n",
            "Epoch 212/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 213/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 214/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8644\n",
            "Epoch 215/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8644\n",
            "Epoch 216/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8637\n",
            "Epoch 217/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8639\n",
            "Epoch 218/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8641\n",
            "Epoch 219/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8631\n",
            "Epoch 220/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8639\n",
            "Epoch 221/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8644\n",
            "Epoch 222/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8648\n",
            "Epoch 223/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8644\n",
            "Epoch 224/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8641\n",
            "Epoch 225/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8646\n",
            "Epoch 226/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8649\n",
            "Epoch 227/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8631\n",
            "Epoch 228/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 229/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8629\n",
            "Epoch 230/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8649\n",
            "Epoch 231/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 232/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8634\n",
            "Epoch 233/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8645\n",
            "Epoch 234/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8652\n",
            "Epoch 235/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8648\n",
            "Epoch 236/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8629\n",
            "Epoch 237/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8662\n",
            "Epoch 238/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8639\n",
            "Epoch 239/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8640\n",
            "Epoch 240/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8648\n",
            "Epoch 241/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8639\n",
            "Epoch 242/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8636\n",
            "Epoch 243/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 244/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 245/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8630\n",
            "Epoch 246/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 247/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8639\n",
            "Epoch 248/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8641\n",
            "Epoch 249/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8635\n",
            "Epoch 250/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8645\n",
            "Epoch 251/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8633\n",
            "Epoch 252/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8648\n",
            "Epoch 253/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8639\n",
            "Epoch 254/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8625\n",
            "Epoch 255/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8645\n",
            "Epoch 256/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8635\n",
            "Epoch 257/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8634\n",
            "Epoch 258/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8651\n",
            "Epoch 259/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8658\n",
            "Epoch 260/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 261/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 262/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8654\n",
            "Epoch 263/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 264/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8652\n",
            "Epoch 265/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 266/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8634\n",
            "Epoch 267/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8648\n",
            "Epoch 268/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8633\n",
            "Epoch 269/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8646\n",
            "Epoch 270/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8641\n",
            "Epoch 271/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8650\n",
            "Epoch 272/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8641\n",
            "Epoch 273/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8658\n",
            "Epoch 274/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 275/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 276/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8648\n",
            "Epoch 277/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8630\n",
            "Epoch 278/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 279/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8649\n",
            "Epoch 280/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8646\n",
            "Epoch 281/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8645\n",
            "Epoch 282/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8659\n",
            "Epoch 283/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 284/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8660\n",
            "Epoch 285/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8645\n",
            "Epoch 286/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8650\n",
            "Epoch 287/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8652\n",
            "Epoch 288/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8662\n",
            "Epoch 289/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8648\n",
            "Epoch 290/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8658\n",
            "Epoch 291/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8650\n",
            "Epoch 292/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8655\n",
            "Epoch 293/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 294/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8659\n",
            "Epoch 295/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8654\n",
            "Epoch 296/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8655\n",
            "Epoch 297/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8633\n",
            "Epoch 298/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8655\n",
            "Epoch 299/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8637\n",
            "Epoch 300/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8660\n",
            "Epoch 301/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8654\n",
            "Epoch 302/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8666\n",
            "Epoch 303/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8664\n",
            "Epoch 304/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 305/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8664\n",
            "Epoch 306/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8649\n",
            "Epoch 307/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8640\n",
            "Epoch 308/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 309/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8646\n",
            "Epoch 310/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8646\n",
            "Epoch 311/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8648\n",
            "Epoch 312/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8656\n",
            "Epoch 313/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8643\n",
            "Epoch 314/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8669\n",
            "Epoch 315/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 316/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8656\n",
            "Epoch 317/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 318/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8671\n",
            "Epoch 319/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 320/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8661\n",
            "Epoch 321/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8664\n",
            "Epoch 322/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8658\n",
            "Epoch 323/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8643\n",
            "Epoch 324/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8644\n",
            "Epoch 325/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 326/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8659\n",
            "Epoch 327/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 328/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8666\n",
            "Epoch 329/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8648\n",
            "Epoch 330/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8641\n",
            "Epoch 331/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8654\n",
            "Epoch 332/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8646\n",
            "Epoch 333/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8656\n",
            "Epoch 334/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8652\n",
            "Epoch 335/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 336/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8655\n",
            "Epoch 337/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8659\n",
            "Epoch 338/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8658\n",
            "Epoch 339/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8654\n",
            "Epoch 340/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8659\n",
            "Epoch 341/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 342/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8649\n",
            "Epoch 343/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 344/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8661\n",
            "Epoch 345/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8659\n",
            "Epoch 346/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8666\n",
            "Epoch 347/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8651\n",
            "Epoch 348/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 349/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8666\n",
            "Epoch 350/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8655\n",
            "Epoch 351/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8655\n",
            "Epoch 352/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8661\n",
            "Epoch 353/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8669\n",
            "Epoch 354/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8650\n",
            "Epoch 355/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8659\n",
            "Epoch 356/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 357/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8665\n",
            "Epoch 358/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8664\n",
            "Epoch 359/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8652\n",
            "Epoch 360/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8656\n",
            "Epoch 361/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8652\n",
            "Epoch 362/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8655\n",
            "Epoch 363/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8656\n",
            "Epoch 364/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8643\n",
            "Epoch 365/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 366/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8651\n",
            "Epoch 367/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8664\n",
            "Epoch 368/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 369/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 370/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8643\n",
            "Epoch 371/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 372/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8662\n",
            "Epoch 373/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8656\n",
            "Epoch 374/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8645\n",
            "Epoch 375/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8656\n",
            "Epoch 376/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8651\n",
            "Epoch 377/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8662\n",
            "Epoch 378/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8658\n",
            "Epoch 379/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8650\n",
            "Epoch 380/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8648\n",
            "Epoch 381/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8652\n",
            "Epoch 382/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8656\n",
            "Epoch 383/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8650\n",
            "Epoch 384/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8651\n",
            "Epoch 385/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8656\n",
            "Epoch 386/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8664\n",
            "Epoch 387/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8664\n",
            "Epoch 388/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8649\n",
            "Epoch 389/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8652\n",
            "Epoch 390/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8661\n",
            "Epoch 391/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8651\n",
            "Epoch 392/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8662\n",
            "Epoch 393/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8659\n",
            "Epoch 394/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8660\n",
            "Epoch 395/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8658\n",
            "Epoch 396/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8654\n",
            "Epoch 397/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8656\n",
            "Epoch 398/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8660\n",
            "Epoch 399/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8646\n",
            "Epoch 400/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8661\n",
            "Epoch 401/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8651\n",
            "Epoch 402/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8650\n",
            "Epoch 403/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8645\n",
            "Epoch 404/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8654\n",
            "Epoch 405/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8660\n",
            "Epoch 406/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8658\n",
            "Epoch 407/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8664\n",
            "Epoch 408/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8660\n",
            "Epoch 409/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8645\n",
            "Epoch 410/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8661\n",
            "Epoch 411/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8661\n",
            "Epoch 412/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8654\n",
            "Epoch 413/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8675\n",
            "Epoch 414/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8671\n",
            "Epoch 415/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8652\n",
            "Epoch 416/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8662\n",
            "Epoch 417/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8661\n",
            "Epoch 418/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8683\n",
            "Epoch 419/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8681\n",
            "Epoch 420/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8658\n",
            "Epoch 421/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8651\n",
            "Epoch 422/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8677\n",
            "Epoch 423/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8660\n",
            "Epoch 424/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8656\n",
            "Epoch 425/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8655\n",
            "Epoch 426/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8655\n",
            "Epoch 427/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8676\n",
            "Epoch 428/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8673\n",
            "Epoch 429/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8658\n",
            "Epoch 430/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8659\n",
            "Epoch 431/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8660\n",
            "Epoch 432/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8675\n",
            "Epoch 433/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8675\n",
            "Epoch 434/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8655\n",
            "Epoch 435/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8659\n",
            "Epoch 436/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8661\n",
            "Epoch 437/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8658\n",
            "Epoch 438/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8640\n",
            "Epoch 439/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8659\n",
            "Epoch 440/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8664\n",
            "Epoch 441/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8668\n",
            "Epoch 442/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8661\n",
            "Epoch 443/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8652\n",
            "Epoch 444/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8664\n",
            "Epoch 445/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8665\n",
            "Epoch 446/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8662\n",
            "Epoch 447/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8660\n",
            "Epoch 448/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8659\n",
            "Epoch 449/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8659\n",
            "Epoch 450/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8666\n",
            "Epoch 451/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8664\n",
            "Epoch 452/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8662\n",
            "Epoch 453/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8664\n",
            "Epoch 454/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8674\n",
            "Epoch 455/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8659\n",
            "Epoch 456/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8658\n",
            "Epoch 457/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8665\n",
            "Epoch 458/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8661\n",
            "Epoch 459/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8665\n",
            "Epoch 460/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8654\n",
            "Epoch 461/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8652\n",
            "Epoch 462/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8665\n",
            "Epoch 463/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8670\n",
            "Epoch 464/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8648\n",
            "Epoch 465/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8654\n",
            "Epoch 466/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8656\n",
            "Epoch 467/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8666\n",
            "Epoch 468/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8668\n",
            "Epoch 469/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8669\n",
            "Epoch 470/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8666\n",
            "Epoch 471/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8660\n",
            "Epoch 472/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8660\n",
            "Epoch 473/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8683\n",
            "Epoch 474/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8662\n",
            "Epoch 475/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8676\n",
            "Epoch 476/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8666\n",
            "Epoch 477/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8668\n",
            "Epoch 478/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8658\n",
            "Epoch 479/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8670\n",
            "Epoch 480/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8669\n",
            "Epoch 481/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8670\n",
            "Epoch 482/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8648\n",
            "Epoch 483/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8666\n",
            "Epoch 484/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8637\n",
            "Epoch 485/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8664\n",
            "Epoch 486/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8664\n",
            "Epoch 487/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8664\n",
            "Epoch 488/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8660\n",
            "Epoch 489/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8664\n",
            "Epoch 490/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8665\n",
            "Epoch 491/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8668\n",
            "Epoch 492/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8656\n",
            "Epoch 493/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8649\n",
            "Epoch 494/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8675\n",
            "Epoch 495/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8679\n",
            "Epoch 496/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8677\n",
            "Epoch 497/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8664\n",
            "Epoch 498/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8673\n",
            "Epoch 499/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8664\n",
            "Epoch 500/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8686\n",
            "Epoch 501/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8671\n",
            "Epoch 502/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8655\n",
            "Epoch 503/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8659\n",
            "Epoch 504/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8661\n",
            "Epoch 505/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8669\n",
            "Epoch 506/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8673\n",
            "Epoch 507/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8651\n",
            "Epoch 508/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8668\n",
            "Epoch 509/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8666\n",
            "Epoch 510/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8669\n",
            "Epoch 511/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8655\n",
            "Epoch 512/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8659\n",
            "Epoch 513/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8676\n",
            "Epoch 514/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8652\n",
            "Epoch 515/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8679\n",
            "Epoch 516/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3266 - accuracy: 0.8676\n",
            "Epoch 517/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.8685\n",
            "Epoch 518/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8659\n",
            "Epoch 519/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8656\n",
            "Epoch 520/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8665\n",
            "Epoch 521/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8670\n",
            "Epoch 522/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8658\n",
            "Epoch 523/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8671\n",
            "Epoch 524/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8674\n",
            "Epoch 525/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8673\n",
            "Epoch 526/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8665\n",
            "Epoch 527/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8666\n",
            "Epoch 528/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8676\n",
            "Epoch 529/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8679\n",
            "Epoch 530/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8670\n",
            "Epoch 531/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8660\n",
            "Epoch 532/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8670\n",
            "Epoch 533/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8659\n",
            "Epoch 534/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8675\n",
            "Epoch 535/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8659\n",
            "Epoch 536/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8645\n",
            "Epoch 537/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8666\n",
            "Epoch 538/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8669\n",
            "Epoch 539/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8680\n",
            "Epoch 540/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8660\n",
            "Epoch 541/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8668\n",
            "Epoch 542/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8671\n",
            "Epoch 543/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8651\n",
            "Epoch 544/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8673\n",
            "Epoch 545/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8662\n",
            "Epoch 546/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8655\n",
            "Epoch 547/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8660\n",
            "Epoch 548/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8670\n",
            "Epoch 549/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8658\n",
            "Epoch 550/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8654\n",
            "Epoch 551/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8671\n",
            "Epoch 552/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8664\n",
            "Epoch 553/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8671\n",
            "Epoch 554/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8661\n",
            "Epoch 555/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8636\n",
            "Epoch 556/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8659\n",
            "Epoch 557/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8664\n",
            "Epoch 558/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8660\n",
            "Epoch 559/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8673\n",
            "Epoch 560/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8668\n",
            "Epoch 561/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8671\n",
            "Epoch 562/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8651\n",
            "Epoch 563/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8651\n",
            "Epoch 564/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8648\n",
            "Epoch 565/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8662\n",
            "Epoch 566/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8668\n",
            "Epoch 567/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8673\n",
            "Epoch 568/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8665\n",
            "Epoch 569/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8674\n",
            "Epoch 570/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8662\n",
            "Epoch 571/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8654\n",
            "Epoch 572/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8661\n",
            "Epoch 573/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8669\n",
            "Epoch 574/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8661\n",
            "Epoch 575/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8652\n",
            "Epoch 576/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8662\n",
            "Epoch 577/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8659\n",
            "Epoch 578/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8662\n",
            "Epoch 579/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8668\n",
            "Epoch 580/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3265 - accuracy: 0.8669\n",
            "Epoch 581/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8660\n",
            "Epoch 582/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8662\n",
            "Epoch 583/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3259 - accuracy: 0.8650\n",
            "Epoch 584/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8664\n",
            "Epoch 585/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8652\n",
            "Epoch 586/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8665\n",
            "Epoch 587/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8662\n",
            "Epoch 588/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8676\n",
            "Epoch 589/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8650\n",
            "Epoch 590/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8659\n",
            "Epoch 591/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8656\n",
            "Epoch 592/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8670\n",
            "Epoch 593/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8666\n",
            "Epoch 594/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8646\n",
            "Epoch 595/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8660\n",
            "Epoch 596/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3259 - accuracy: 0.8676\n",
            "Epoch 597/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3262 - accuracy: 0.8666\n",
            "Epoch 598/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.8662\n",
            "Epoch 599/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8664\n",
            "Epoch 600/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8670\n",
            "Epoch 601/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8674\n",
            "Epoch 602/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8651\n",
            "Epoch 603/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8674\n",
            "Epoch 604/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8669\n",
            "Epoch 605/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8650\n",
            "Epoch 606/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8658\n",
            "Epoch 607/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8652\n",
            "Epoch 608/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8659\n",
            "Epoch 609/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8674\n",
            "Epoch 610/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8659\n",
            "Epoch 611/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8679\n",
            "Epoch 612/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8652\n",
            "Epoch 613/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8673\n",
            "Epoch 614/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8660\n",
            "Epoch 615/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8652\n",
            "Epoch 616/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8656\n",
            "Epoch 617/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8666\n",
            "Epoch 618/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8669\n",
            "Epoch 619/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8660\n",
            "Epoch 620/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8664\n",
            "Epoch 621/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8649\n",
            "Epoch 622/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8665\n",
            "Epoch 623/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3259 - accuracy: 0.8660\n",
            "Epoch 624/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8643\n",
            "Epoch 625/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3259 - accuracy: 0.8661\n",
            "Epoch 626/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8660\n",
            "Epoch 627/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.8670\n",
            "Epoch 628/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8659\n",
            "Epoch 629/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8660\n",
            "Epoch 630/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8662\n",
            "Epoch 631/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8670\n",
            "Epoch 632/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8659\n",
            "Epoch 633/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8673\n",
            "Epoch 634/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8661\n",
            "Epoch 635/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8661\n",
            "Epoch 636/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8671\n",
            "Epoch 637/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8660\n",
            "Epoch 638/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8668\n",
            "Epoch 639/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8649\n",
            "Epoch 640/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8661\n",
            "Epoch 641/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8666\n",
            "Epoch 642/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8666\n",
            "Epoch 643/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8650\n",
            "Epoch 644/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8673\n",
            "Epoch 645/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8666\n",
            "Epoch 646/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8666\n",
            "Epoch 647/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8660\n",
            "Epoch 648/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8661\n",
            "Epoch 649/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8669\n",
            "Epoch 650/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8686\n",
            "Epoch 651/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8655\n",
            "Epoch 652/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8666\n",
            "Epoch 653/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8668\n",
            "Epoch 654/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8664\n",
            "Epoch 655/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8655\n",
            "Epoch 656/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8641\n",
            "Epoch 657/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8671\n",
            "Epoch 658/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8662\n",
            "Epoch 659/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8658\n",
            "Epoch 660/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8665\n",
            "Epoch 661/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8658\n",
            "Epoch 662/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8659\n",
            "Epoch 663/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8649\n",
            "Epoch 664/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8650\n",
            "Epoch 665/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8661\n",
            "Epoch 666/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8659\n",
            "Epoch 667/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8668\n",
            "Epoch 668/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8651\n",
            "Epoch 669/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8665\n",
            "Epoch 670/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8646\n",
            "Epoch 671/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8659\n",
            "Epoch 672/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8676\n",
            "Epoch 673/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8661\n",
            "Epoch 674/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8665\n",
            "Epoch 675/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8659\n",
            "Epoch 676/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8661\n",
            "Epoch 677/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8651\n",
            "Epoch 678/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8656\n",
            "Epoch 679/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8659\n",
            "Epoch 680/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8681\n",
            "Epoch 681/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8681\n",
            "Epoch 682/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8646\n",
            "Epoch 683/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8654\n",
            "Epoch 684/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8659\n",
            "Epoch 685/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8676\n",
            "Epoch 686/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8680\n",
            "Epoch 687/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8679\n",
            "Epoch 688/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8656\n",
            "Epoch 689/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8660\n",
            "Epoch 690/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8666\n",
            "Epoch 691/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8660\n",
            "Epoch 692/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8674\n",
            "Epoch 693/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8652\n",
            "Epoch 694/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8651\n",
            "Epoch 695/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8658\n",
            "Epoch 696/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8680\n",
            "Epoch 697/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8650\n",
            "Epoch 698/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8649\n",
            "Epoch 699/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8658\n",
            "Epoch 700/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8646\n",
            "Epoch 701/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8671\n",
            "Epoch 702/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8669\n",
            "Epoch 703/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8656\n",
            "Epoch 704/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8656\n",
            "Epoch 705/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3245 - accuracy: 0.8656\n",
            "Epoch 706/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3243 - accuracy: 0.8659\n",
            "Epoch 707/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3242 - accuracy: 0.8676\n",
            "Epoch 708/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3249 - accuracy: 0.8666\n",
            "Epoch 709/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8661\n",
            "Epoch 710/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8655\n",
            "Epoch 711/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8670\n",
            "Epoch 712/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8651\n",
            "Epoch 713/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3242 - accuracy: 0.8670\n",
            "Epoch 714/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8673\n",
            "Epoch 715/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8654\n",
            "Epoch 716/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.8655\n",
            "Epoch 717/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3242 - accuracy: 0.8660\n",
            "Epoch 718/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8660\n",
            "Epoch 719/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8662\n",
            "Epoch 720/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8650\n",
            "Epoch 721/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8659\n",
            "Epoch 722/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8651\n",
            "Epoch 723/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8668\n",
            "Epoch 724/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8648\n",
            "Epoch 725/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8662\n",
            "Epoch 726/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8661\n",
            "Epoch 727/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8656\n",
            "Epoch 728/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8671\n",
            "Epoch 729/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8660\n",
            "Epoch 730/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8662\n",
            "Epoch 731/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8654\n",
            "Epoch 732/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8654\n",
            "Epoch 733/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8664\n",
            "Epoch 734/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8665\n",
            "Epoch 735/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8652\n",
            "Epoch 736/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8651\n",
            "Epoch 737/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8655\n",
            "Epoch 738/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8665\n",
            "Epoch 739/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8659\n",
            "Epoch 740/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8660\n",
            "Epoch 741/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8658\n",
            "Epoch 742/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8659\n",
            "Epoch 743/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8673\n",
            "Epoch 744/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8666\n",
            "Epoch 745/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8652\n",
            "Epoch 746/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8650\n",
            "Epoch 747/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8652\n",
            "Epoch 748/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8655\n",
            "Epoch 749/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8648\n",
            "Epoch 750/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8644\n",
            "Epoch 751/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8661\n",
            "Epoch 752/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8656\n",
            "Epoch 753/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8674\n",
            "Epoch 754/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8668\n",
            "Epoch 755/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8655\n",
            "Epoch 756/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8655\n",
            "Epoch 757/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8666\n",
            "Epoch 758/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8671\n",
            "Epoch 759/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8665\n",
            "Epoch 760/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8666\n",
            "Epoch 761/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8683\n",
            "Epoch 762/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8658\n",
            "Epoch 763/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8675\n",
            "Epoch 764/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8662\n",
            "Epoch 765/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8668\n",
            "Epoch 766/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8660\n",
            "Epoch 767/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8670\n",
            "Epoch 768/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8666\n",
            "Epoch 769/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8644\n",
            "Epoch 770/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8655\n",
            "Epoch 771/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8673\n",
            "Epoch 772/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8664\n",
            "Epoch 773/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8654\n",
            "Epoch 774/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8664\n",
            "Epoch 775/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8662\n",
            "Epoch 776/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8689\n",
            "Epoch 777/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8645\n",
            "Epoch 778/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8651\n",
            "Epoch 779/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8671\n",
            "Epoch 780/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8665\n",
            "Epoch 781/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8668\n",
            "Epoch 782/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8674\n",
            "Epoch 783/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8676\n",
            "Epoch 784/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8654\n",
            "Epoch 785/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8673\n",
            "Epoch 786/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8664\n",
            "Epoch 787/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8676\n",
            "Epoch 788/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8664\n",
            "Epoch 789/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8650\n",
            "Epoch 790/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8665\n",
            "Epoch 791/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8669\n",
            "Epoch 792/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8654\n",
            "Epoch 793/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8669\n",
            "Epoch 794/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8666\n",
            "Epoch 795/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8655\n",
            "Epoch 796/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8659\n",
            "Epoch 797/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8659\n",
            "Epoch 798/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8685\n",
            "Epoch 799/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8649\n",
            "Epoch 800/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8661\n",
            "Epoch 801/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8673\n",
            "Epoch 802/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8658\n",
            "Epoch 803/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8671\n",
            "Epoch 804/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8660\n",
            "Epoch 805/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8681\n",
            "Epoch 806/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8656\n",
            "Epoch 807/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8665\n",
            "Epoch 808/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8683\n",
            "Epoch 809/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8659\n",
            "Epoch 810/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8655\n",
            "Epoch 811/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8669\n",
            "Epoch 812/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8662\n",
            "Epoch 813/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8666\n",
            "Epoch 814/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8651\n",
            "Epoch 815/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8655\n",
            "Epoch 816/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8669\n",
            "Epoch 817/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8650\n",
            "Epoch 818/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8658\n",
            "Epoch 819/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8675\n",
            "Epoch 820/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8662\n",
            "Epoch 821/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8660\n",
            "Epoch 822/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8680\n",
            "Epoch 823/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8665\n",
            "Epoch 824/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8673\n",
            "Epoch 825/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8659\n",
            "Epoch 826/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8675\n",
            "Epoch 827/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8665\n",
            "Epoch 828/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8659\n",
            "Epoch 829/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8654\n",
            "Epoch 830/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8675\n",
            "Epoch 831/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8644\n",
            "Epoch 832/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8654\n",
            "Epoch 833/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8658\n",
            "Epoch 834/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8665\n",
            "Epoch 835/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8652\n",
            "Epoch 836/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8661\n",
            "Epoch 837/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8684\n",
            "Epoch 838/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8664\n",
            "Epoch 839/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8650\n",
            "Epoch 840/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8684\n",
            "Epoch 841/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8671\n",
            "Epoch 842/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8677\n",
            "Epoch 843/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8654\n",
            "Epoch 844/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8669\n",
            "Epoch 845/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8680\n",
            "Epoch 846/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8674\n",
            "Epoch 847/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8652\n",
            "Epoch 848/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8661\n",
            "Epoch 849/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8673\n",
            "Epoch 850/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8662\n",
            "Epoch 851/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8671\n",
            "Epoch 852/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8670\n",
            "Epoch 853/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8675\n",
            "Epoch 854/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8675\n",
            "Epoch 855/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8661\n",
            "Epoch 856/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8668\n",
            "Epoch 857/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8677\n",
            "Epoch 858/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8661\n",
            "Epoch 859/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8673\n",
            "Epoch 860/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8675\n",
            "Epoch 861/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8659\n",
            "Epoch 862/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8677\n",
            "Epoch 863/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8656\n",
            "Epoch 864/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8669\n",
            "Epoch 865/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8669\n",
            "Epoch 866/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8677\n",
            "Epoch 867/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8673\n",
            "Epoch 868/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8662\n",
            "Epoch 869/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8660\n",
            "Epoch 870/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8684\n",
            "Epoch 871/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8675\n",
            "Epoch 872/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8673\n",
            "Epoch 873/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8669\n",
            "Epoch 874/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.8676\n",
            "Epoch 875/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8654\n",
            "Epoch 876/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8655\n",
            "Epoch 877/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8658\n",
            "Epoch 878/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8681\n",
            "Epoch 879/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8666\n",
            "Epoch 880/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8664\n",
            "Epoch 881/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8675\n",
            "Epoch 882/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8675\n",
            "Epoch 883/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8661\n",
            "Epoch 884/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8673\n",
            "Epoch 885/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8668\n",
            "Epoch 886/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8668\n",
            "Epoch 887/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8659\n",
            "Epoch 888/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8675\n",
            "Epoch 889/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8671\n",
            "Epoch 890/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8662\n",
            "Epoch 891/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8671\n",
            "Epoch 892/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8664\n",
            "Epoch 893/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8669\n",
            "Epoch 894/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8675\n",
            "Epoch 895/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8669\n",
            "Epoch 896/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8676\n",
            "Epoch 897/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8669\n",
            "Epoch 898/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.8658\n",
            "Epoch 899/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8669\n",
            "Epoch 900/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8680\n",
            "Epoch 901/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8670\n",
            "Epoch 902/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8669\n",
            "Epoch 903/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.8661\n",
            "Epoch 904/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8665\n",
            "Epoch 905/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8664\n",
            "Epoch 906/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8671\n",
            "Epoch 907/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8680\n",
            "Epoch 908/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8661\n",
            "Epoch 909/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8675\n",
            "Epoch 910/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8662\n",
            "Epoch 911/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8669\n",
            "Epoch 912/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8665\n",
            "Epoch 913/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8666\n",
            "Epoch 914/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8674\n",
            "Epoch 915/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8664\n",
            "Epoch 916/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8669\n",
            "Epoch 917/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8665\n",
            "Epoch 918/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8658\n",
            "Epoch 919/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8670\n",
            "Epoch 920/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8656\n",
            "Epoch 921/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8683\n",
            "Epoch 922/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8684\n",
            "Epoch 923/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3232 - accuracy: 0.8668\n",
            "Epoch 924/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8654\n",
            "Epoch 925/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8673\n",
            "Epoch 926/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8669\n",
            "Epoch 927/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3236 - accuracy: 0.8676\n",
            "Epoch 928/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8679\n",
            "Epoch 929/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8675\n",
            "Epoch 930/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8660\n",
            "Epoch 931/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8665\n",
            "Epoch 932/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8664\n",
            "Epoch 933/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8676\n",
            "Epoch 934/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8665\n",
            "Epoch 935/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8679\n",
            "Epoch 936/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8671\n",
            "Epoch 937/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8674\n",
            "Epoch 938/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3233 - accuracy: 0.8673\n",
            "Epoch 939/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8674\n",
            "Epoch 940/1000\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3233 - accuracy: 0.8670\n",
            "Epoch 941/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8680\n",
            "Epoch 942/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8676\n",
            "Epoch 943/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8668\n",
            "Epoch 944/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8668\n",
            "Epoch 945/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8670\n",
            "Epoch 946/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8677\n",
            "Epoch 947/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8674\n",
            "Epoch 948/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8666\n",
            "Epoch 949/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8671\n",
            "Epoch 950/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8677\n",
            "Epoch 951/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8674\n",
            "Epoch 952/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3232 - accuracy: 0.8661\n",
            "Epoch 953/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8656\n",
            "Epoch 954/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8676\n",
            "Epoch 955/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8673\n",
            "Epoch 956/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8674\n",
            "Epoch 957/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8680\n",
            "Epoch 958/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8673\n",
            "Epoch 959/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8680\n",
            "Epoch 960/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8669\n",
            "Epoch 961/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8656\n",
            "Epoch 962/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8674\n",
            "Epoch 963/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8666\n",
            "Epoch 964/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8676\n",
            "Epoch 965/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8684\n",
            "Epoch 966/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8676\n",
            "Epoch 967/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8673\n",
            "Epoch 968/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8673\n",
            "Epoch 969/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8674\n",
            "Epoch 970/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8676\n",
            "Epoch 971/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8658\n",
            "Epoch 972/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8673\n",
            "Epoch 973/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8673\n",
            "Epoch 974/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8673\n",
            "Epoch 975/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8668\n",
            "Epoch 976/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8660\n",
            "Epoch 977/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8659\n",
            "Epoch 978/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8669\n",
            "Epoch 979/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8685\n",
            "Epoch 980/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8671\n",
            "Epoch 981/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8681\n",
            "Epoch 982/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8658\n",
            "Epoch 983/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8681\n",
            "Epoch 984/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8685\n",
            "Epoch 985/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8677\n",
            "Epoch 986/1000\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8662\n",
            "Epoch 987/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8668\n",
            "Epoch 988/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8675\n",
            "Epoch 989/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8666\n",
            "Epoch 990/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8670\n",
            "Epoch 991/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8676\n",
            "Epoch 992/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8676\n",
            "Epoch 993/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8664\n",
            "Epoch 994/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8655\n",
            "Epoch 995/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8654\n",
            "Epoch 996/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8661\n",
            "Epoch 997/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8670\n",
            "Epoch 998/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8665\n",
            "Epoch 999/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8671\n",
            "Epoch 1000/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f450033fa00>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "ann.fit(x_train, y_train, batch_size = 32, epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ann_visualizer.visualize import ann_viz\n",
        "ann_viz(ann, title=\"My first neural network\", view=True, filename=\"network.gv\")"
      ],
      "metadata": {
        "id": "Af8XK27SibhA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(ann, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "5gUeH3pdicgG",
        "outputId": "9202cee4-a6e3-4142-c53f-eca57bd38cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import visualkeras\n",
        "visualkeras.layered_view(ann, legend=True, draw_volume=False)"
      ],
      "metadata": {
        "id": "E4ZjdpWukFKW",
        "outputId": "3fae6e27-5eda-429c-b2e0-5489d9a8cac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=100x51 at 0x7F4503794730>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAAzCAYAAABhaa0bAAABrUlEQVR4nO3aMU7DMBiG4f8vLIysmUDiBpSByWLoCXoKhl6gUyYuwMApEAdgIQss3ThAp3bogoSExGYmo+AmsS0M/ZJ+z1SaEFd+FbdKotZaKwHlfCbV472YcRHaNUq1WMtyM5KT07PO/T7fV3J08DGIcc1kKuXNbXDfw9iDmnEh5fX5rz6YU96JmOPL4Acs5zORt5dBjBtrlGVEyoZBwDAIGAYBwyBgGAQMg4BhEDAMAoZBwDAIGAYBwyBgGAQMg4BhEDAMAib6jmG1WCfd+Qoda7l5kKfn18793K3UIYxrJnH7asw9dfo/XLLAMAgYBgHDIGAYBAyDgGEQMAwChkHARF86ubooop4GT3nSm7Zlf/o91/WffcUlC0z0GfIXVPXH37zOueMgjrVWVFVU9TtKPZbb3vTaaYvrHwcd5JLlT7gfyp9sf9L97U1xUEEGcWIn0D9T/P/rQwgHYslqk7LEhM6avoAI4i8t9e8Up2tSm86AeqA+xdlpkK7JadpWf6/tdcoYiLI/5JByQ5+28SEHMNC/svYRg4BhEDAMAoZBwDAIGAYBwyBgGATMFznRviKoNzgAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwvYoI5ViiWu",
        "outputId": "a31cc050-5f75-415a-da15-03e44c3d190e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 192ms/step\n",
            "[[False]]\n"
          ]
        }
      ],
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCYM-du9iiWu",
        "outputId": "71454b28-cfe7-48ab-f46f-b9ffd799ae30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n",
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = ann.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnDBkp3tiiWv",
        "outputId": "11ce579f-aee5-4d67-dad1-5a52e0d08023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1529   56]\n",
            " [ 197  218]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8735"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}